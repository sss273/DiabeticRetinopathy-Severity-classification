{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "7E0d1ItJG6pB",
    "outputId": "d28ce344-2a20-41b8-d241-c16aa8187799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CqW8SV4FiJ6x"
   },
   "outputs": [],
   "source": [
    "!cp ./drive/My\\ Drive/Dataset\\ DR/colored.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06ukZtqoiizf"
   },
   "outputs": [],
   "source": [
    "!unzip colored.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jeejsdVfR0L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "gHIlgeDHf18f",
    "outputId": "7a4fe886-29d9-4b1a-d366-a311f6845b9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C5wDZwFkf5Py"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "#from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.densenet import DenseNet121,DenseNet169\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imgaug as ia\n",
    "\n",
    "WORKERS = 2\n",
    "CHANNEL = 3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 300\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIBZWXTjf8jq"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('trainLabels.csv')\n",
    "updated_labels = pd.DataFrame()\n",
    "updated_labels['image'] = labels['image']\n",
    "updated_labels['level'] = labels['level']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yV_vW5yehLay"
   },
   "outputs": [],
   "source": [
    "root_directory = './colored'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNvMVPrShKwH"
   },
   "outputs": [],
   "source": [
    "check_path = os.path.exists\n",
    "split_name = lambda x: x.split('_')[0]\n",
    "image_path = lambda x: os.path.join(root_directory,'{}.jpeg'.format(x))\n",
    "get_level  = lambda x: to_categorical(x,1+dataset['level'].max())\n",
    "check_left_or_right = lambda x: 1 if x.split('_')[-1]=='left' else 0\n",
    "resample_data = lambda x: x.sample(300, replace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_u-y3wZMhNJF"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()\n",
    "\n",
    "dataset['image'] = updated_labels['image']\n",
    "dataset['level'] = updated_labels['level']\n",
    "\n",
    "dataset['p_id'] = updated_labels['image'].map(split_name)\n",
    "dataset['path'] = updated_labels['image'].map(image_path)\n",
    "\n",
    "dataset['path_exists'] = dataset['path'].map(check_path)\n",
    "dataset['l_r_eye'] = dataset['image'].map(check_left_or_right)\n",
    "dataset['level_cat'] = dataset['level'].map(get_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4OpTHU_MhPUP",
    "outputId": "671fc2b5-2b5b-482d-a5d3-e624653fd7e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35126, 7)\n",
      "(2500, 7)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "# Removing nulls and rows where path does not exist (since we are working on a subset)\n",
    "dataset.dropna(inplace = True)\n",
    "dataset = dataset[dataset['path_exists']]\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "a0RyJi86hRd1",
    "outputId": "2f174747-cc21-434b-e1e7-32bf6f02f4d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f792e710d30>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f792e70b518>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAE/CAYAAACTlB3ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[['level', 'l_r_eye']].hist(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "TPPQ6vWrjLHs",
    "outputId": "6456444a-5e79-4031-eee7-67b829f99ae5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f792e773cf8>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = dataset['path']\n",
    "y = dataset['level']\n",
    "\n",
    "x, y = shuffle(x, y, random_state=8)\n",
    "y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "B2by2zAjkUV7",
    "outputId": "ebdcb4a3-9150-420f-b578-9e1597e30ae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2125,)\n",
      "(2125, 5)\n",
      "(375,)\n",
      "(375, 5)\n"
     ]
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=NUM_CLASSES)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,stratify=y, random_state=8)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQMlt2BekZJ3"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential(\n",
    "        [\n",
    "            # apply the following augmenters to most images\n",
    "            iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "            iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "            sometimes(iaa.Affine(\n",
    "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
    "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
    "                rotate=(-10, 10), # rotate by -45 to +45 degrees\n",
    "                shear=(-5, 5), # shear by -16 to +16 degrees\n",
    "                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "                mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "            )),\n",
    "            # execute 0 to 5 of the following (less important) augmenters per image\n",
    "            # don't execute all of them, as that would often be way too strong\n",
    "            iaa.SomeOf((0, 5),\n",
    "                [\n",
    "                    sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                    iaa.OneOf([\n",
    "                        iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
    "                        iaa.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                        iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                    ]),\n",
    "                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n",
    "                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
    "                    # search either for all edges or for directed edges,\n",
    "                    # blend the result with the original image using a blobby mask\n",
    "                    iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                        iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
    "                        iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                    ])),\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n",
    "                    iaa.OneOf([\n",
    "                        iaa.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                        iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
    "                    ]),\n",
    "                    iaa.Invert(0.01, per_channel=True), # invert color channels\n",
    "                    iaa.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                    iaa.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n",
    "                    # either change the brightness of the whole image (sometimes\n",
    "                    # per channel) or change the brightness of subareas\n",
    "                    iaa.OneOf([\n",
    "                        iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "                        iaa.FrequencyNoiseAlpha(\n",
    "                            exponent=(-1, 0),\n",
    "                            first=iaa.Multiply((0.9, 1.1), per_channel=True),\n",
    "                            second=iaa.ContrastNormalization((0.9, 1.1))\n",
    "                        )\n",
    "                    ]),\n",
    "                    sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "                    sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
    "                    sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "                ],\n",
    "                random_order=True\n",
    "            )\n",
    "        ],\n",
    "        random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RW6WFmaWkrf_"
   },
   "outputs": [],
   "source": [
    "class My_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, labels,batch_size, is_train=True,mix=False, augment=False):\n",
    "        self.image_filenames, self.labels = image_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.is_train = is_train\n",
    "        self.is_augment = augment\n",
    "        if(self.is_train):\n",
    "            self.on_epoch_end()\n",
    "        self.is_mix = mix\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        if(self.is_train):\n",
    "            return self.train_generate(batch_x, batch_y)\n",
    "        return self.valid_generate(batch_x, batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if(self.is_train):\n",
    "            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def mix_up(self, x, y):\n",
    "        lam = np.random.beta(0.2, 0.4)\n",
    "        ori_index = np.arange(int(len(x)))\n",
    "        index_array = np.arange(int(len(x)))\n",
    "        np.random.shuffle(index_array)        \n",
    "        \n",
    "        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n",
    "        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n",
    "        \n",
    "        return mixed_x, mixed_y\n",
    "\n",
    "    def train_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            # img = cv2.imread('./colored/'+sample+'.jpeg')\n",
    "            img = cv2.imread(sample)\n",
    "            img = cv2.resize(img, (SIZE, SIZE))\n",
    "            if(self.is_augment):\n",
    "                img = seq.augment_image(img)\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        if(self.is_mix):\n",
    "            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n",
    "        return batch_images, batch_y\n",
    "\n",
    "    def valid_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            # img = cv2.imread('./colored/'+sample+'.jpeg')\n",
    "            img = cv2.imread(sample)\n",
    "            img = cv2.resize(img, (SIZE, SIZE))\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        return batch_images, batch_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "peNAuwUOlGwN"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = DenseNet121(include_top=False,weights='imagenet',input_tensor=input_tensor)\n",
    "\n",
    "    # base_model.load_weights(\"../input/densenet-keras/DenseNet-BC-121-32-no-top.h5\")\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    final_output = Dense(n_out, activation='softmax', name='final_output')(x)\n",
    "    model = Model(input_tensor, final_output) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "colab_type": "code",
    "id": "ncIOasF5lqCE",
    "outputId": "ddb54652-6da4-421c-ad92-b1f0e75987bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "\n",
    "epochs = 30; batch_size = 16\n",
    "checkpoint = ModelCheckpoint('./densenet_.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=9)\n",
    "\n",
    "csv_logger = CSVLogger(filename='./training_log.csv',separator=',',append=True)\n",
    "\n",
    "train_generator = My_Generator(train_x, train_y, batch_size, is_train=True)\n",
    "train_mixup = My_Generator(train_x, train_y, batch_size, is_train=True, mix=False, augment=True)\n",
    "valid_generator = My_Generator(valid_x, valid_y, batch_size, is_train=False)\n",
    "\n",
    "model = create_model(input_shape=(SIZE,SIZE,3), n_out=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwVFgJnyl6yf"
   },
   "outputs": [],
   "source": [
    "def kappa_loss(y_true, y_pred, y_pow=2, eps=1e-12, N=5, bsize=32, name='kappa'):\n",
    "    \"\"\"A continuous differentiable approximation of discrete kappa loss.\n",
    "        Args:\n",
    "            y_pred: 2D tensor or array, [batch_size, num_classes]\n",
    "            y_true: 2D tensor or array,[batch_size, num_classes]\n",
    "            y_pow: int,  e.g. y_pow=2\n",
    "            N: typically num_classes of the model\n",
    "            bsize: batch_size of the training or validation ops\n",
    "            eps: a float, prevents divide by zero\n",
    "            name: Optional scope/name for op_scope.\n",
    "        Returns:\n",
    "            A tensor with the kappa loss.\"\"\"\n",
    "\n",
    "    with tf.name_scope(name):\n",
    "        y_true = tf.to_float(y_true)\n",
    "        repeat_op = tf.to_float(tf.tile(tf.reshape(tf.range(0, N), [N, 1]), [1, N]))\n",
    "        repeat_op_sq = tf.square((repeat_op - tf.transpose(repeat_op)))\n",
    "        weights = repeat_op_sq / tf.to_float((N - 1) ** 2)\n",
    "    \n",
    "        pred_ = y_pred ** y_pow\n",
    "        try:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [-1, 1]))\n",
    "        except Exception:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [bsize, 1]))\n",
    "    \n",
    "        hist_rater_a = tf.reduce_sum(pred_norm, 0)\n",
    "        hist_rater_b = tf.reduce_sum(y_true, 0)\n",
    "    \n",
    "        conf_mat = tf.matmul(tf.transpose(pred_norm), y_true)\n",
    "    \n",
    "        nom = tf.reduce_sum(weights * conf_mat)\n",
    "        denom = tf.reduce_sum(weights * tf.matmul(\n",
    "            tf.reshape(hist_rater_a, [N, 1]), tf.reshape(hist_rater_b, [1, N])) /\n",
    "                              tf.to_float(bsize))\n",
    "    \n",
    "        return nom*0.5 / (denom + eps) + categorical_crossentropy(y_true, y_pred)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5FQ_TuNmROe"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class QWKEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), batch_size=64, interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.batch_size = batch_size\n",
    "        self.valid_generator, self.y_val = validation_data\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict_generator(generator=self.valid_generator,\n",
    "                                                  steps=np.ceil(float(len(self.y_val)) / float(self.batch_size)),\n",
    "                                                  workers=1, use_multiprocessing=False,\n",
    "                                                  verbose=1)\n",
    "            def flatten(y):\n",
    "                return np.argmax(y, axis=1).reshape(-1)\n",
    "            \n",
    "            score = cohen_kappa_score(flatten(self.y_val),\n",
    "                                      flatten(y_pred),\n",
    "                                      labels=[0,1,2,3,4],\n",
    "                                      weights='quadratic')\n",
    "            print(\"\\n epoch: %d - QWK_score: %.6f \\n\" % (epoch+1, score))\n",
    "            self.history.append(score)\n",
    "            if score >= max(self.history):\n",
    "                print('saving checkpoint: ', score)\n",
    "                self.model.save('./working/densenet_bestqwk.h5')\n",
    "\n",
    "qwk = QWKEvaluation(validation_data=(valid_generator, valid_y),batch_size=batch_size, interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "r6Dx6X9RmVV6",
    "outputId": "77401384-62e6-4167-e8c8-fb016ccaa6fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/2\n",
      "17/17 [==============================] - 12s 681ms/step - loss: 2.5545\n",
      "24/24 [==============================] - 11s 451ms/step\n",
      "\n",
      " epoch: 1 - QWK_score: 0.065491 \n",
      "\n",
      "saving checkpoint:  0.06549118387909325\n",
      "Epoch 2/2\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 2.2309\n",
      "24/24 [==============================] - 6s 248ms/step\n",
      "\n",
      " epoch: 2 - QWK_score: 0.173317 \n",
      "\n",
      "saving checkpoint:  0.17331670822942635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f78d3b9e668>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warm up model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i in range(-3,0):\n",
    "    model.layers[i].trainable = True\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(1e-3))\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_y)) / float(128)),\n",
    "    epochs=2,\n",
    "    workers=1, use_multiprocessing=False,\n",
    "    verbose=1,\n",
    "    callbacks=[qwk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vNpRGZErmZ-k",
    "outputId": "43abcc3b-fcf7-41f5-ec83-9f6af893a634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "133/133 [==============================] - 171s 1s/step - loss: 1.9265 - val_loss: 1.2742\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.27420, saving model to ./densenet_.h5\n",
      "24/24 [==============================] - 10s 404ms/step\n",
      "\n",
      " epoch: 1 - QWK_score: 0.655895 \n",
      "\n",
      "saving checkpoint:  0.6558946738479952\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 126s 949ms/step - loss: 1.5826 - val_loss: 1.2232\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.27420 to 1.22318, saving model to ./densenet_.h5\n",
      "24/24 [==============================] - 7s 279ms/step\n",
      "\n",
      " epoch: 2 - QWK_score: 0.702314 \n",
      "\n",
      "saving checkpoint:  0.7023144453312051\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 127s 952ms/step - loss: 1.4574 - val_loss: 1.1963\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.22318 to 1.19631, saving model to ./densenet_.h5\n",
      "24/24 [==============================] - 7s 301ms/step\n",
      "\n",
      " epoch: 3 - QWK_score: 0.660826 \n",
      "\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 131s 986ms/step - loss: 1.3567 - val_loss: 1.1584\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.19631 to 1.15835, saving model to ./densenet_.h5\n",
      "24/24 [==============================] - 7s 301ms/step\n",
      "\n",
      " epoch: 4 - QWK_score: 0.680412 \n",
      "\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 128s 965ms/step - loss: 1.3125 - val_loss: 1.1205\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.15835 to 1.12053, saving model to ./densenet_.h5\n",
      "24/24 [==============================] - 7s 293ms/step\n",
      "\n",
      " epoch: 5 - QWK_score: 0.749398 \n",
      "\n",
      "saving checkpoint:  0.7493975903614458\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 129s 973ms/step - loss: 1.2858 - val_loss: 1.1822\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.12053\n",
      "24/24 [==============================] - 7s 295ms/step\n",
      "\n",
      " epoch: 6 - QWK_score: 0.678020 \n",
      "\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 128s 965ms/step - loss: 1.2378 - val_loss: 1.1025\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.12053 to 1.10253, saving model to ./densenet_.h5\n",
      "24/24 [==============================] - 7s 305ms/step\n",
      "\n",
      " epoch: 7 - QWK_score: 0.702884 \n",
      "\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 128s 963ms/step - loss: 1.2461 - val_loss: 1.2410\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.10253\n",
      "24/24 [==============================] - 7s 310ms/step\n",
      "\n",
      " epoch: 8 - QWK_score: 0.692055 \n",
      "\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 128s 965ms/step - loss: 1.2224 - val_loss: 1.1115\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.10253\n",
      "24/24 [==============================] - 8s 316ms/step\n",
      "\n",
      " epoch: 9 - QWK_score: 0.748882 \n",
      "\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 129s 969ms/step - loss: 1.1746 - val_loss: 1.0763\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.10253 to 1.07627, saving model to ./densenet_.h5\n",
      "24/24 [==============================] - 7s 308ms/step\n",
      "\n",
      " epoch: 10 - QWK_score: 0.712383 \n",
      "\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 127s 957ms/step - loss: 1.1685 - val_loss: 1.0613\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.07627 to 1.06131, saving model to ./densenet_.h5\n",
      "24/24 [==============================] - 7s 288ms/step\n",
      "\n",
      " epoch: 11 - QWK_score: 0.763691 \n",
      "\n",
      "saving checkpoint:  0.7636909227306826\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 127s 956ms/step - loss: 1.1643 - val_loss: 1.0790\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.06131\n",
      "24/24 [==============================] - 7s 300ms/step\n",
      "\n",
      " epoch: 12 - QWK_score: 0.763826 \n",
      "\n",
      "saving checkpoint:  0.7638256343526351\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 128s 960ms/step - loss: 1.1274 - val_loss: 1.3035\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.06131\n",
      "24/24 [==============================] - 7s 312ms/step\n",
      "\n",
      " epoch: 13 - QWK_score: 0.607735 \n",
      "\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 125s 938ms/step - loss: 1.1213 - val_loss: 1.0522\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.06131 to 1.05225, saving model to ./densenet_.h5\n",
      "24/24 [==============================] - 7s 303ms/step\n",
      "\n",
      " epoch: 14 - QWK_score: 0.758398 \n",
      "\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 129s 971ms/step - loss: 1.1253 - val_loss: 1.2889\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.05225\n",
      "24/24 [==============================] - 7s 310ms/step\n",
      "\n",
      " epoch: 15 - QWK_score: 0.750000 \n",
      "\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 127s 953ms/step - loss: 1.1050 - val_loss: 1.0565\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.05225\n",
      "24/24 [==============================] - 8s 316ms/step\n",
      "\n",
      " epoch: 16 - QWK_score: 0.770213 \n",
      "\n",
      "saving checkpoint:  0.7702127659574468\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 127s 952ms/step - loss: 1.0907 - val_loss: 1.1931\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.05225\n",
      "24/24 [==============================] - 7s 306ms/step\n",
      "\n",
      " epoch: 17 - QWK_score: 0.697590 \n",
      "\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 130s 979ms/step - loss: 1.0697 - val_loss: 1.2211\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.05225\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "24/24 [==============================] - 6s 260ms/step\n",
      "\n",
      " epoch: 18 - QWK_score: 0.751199 \n",
      "\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 127s 952ms/step - loss: 1.0210 - val_loss: 1.0348\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.05225 to 1.03484, saving model to ./densenet_.h5\n",
      "24/24 [==============================] - 7s 292ms/step\n",
      "\n",
      " epoch: 19 - QWK_score: 0.749164 \n",
      "\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 127s 957ms/step - loss: 0.9833 - val_loss: 1.0480\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.03484\n",
      "24/24 [==============================] - 7s 308ms/step\n",
      "\n",
      " epoch: 20 - QWK_score: 0.759628 \n",
      "\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 130s 979ms/step - loss: 0.9708 - val_loss: 1.0760\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.03484\n",
      "24/24 [==============================] - 8s 315ms/step\n",
      "\n",
      " epoch: 21 - QWK_score: 0.789668 \n",
      "\n",
      "saving checkpoint:  0.7896678966789668\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 127s 958ms/step - loss: 0.9891 - val_loss: 1.0590\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.03484\n",
      "24/24 [==============================] - 7s 300ms/step\n",
      "\n",
      " epoch: 22 - QWK_score: 0.771102 \n",
      "\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 123s 926ms/step - loss: 0.9446 - val_loss: 1.0510\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.03484\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "24/24 [==============================] - 8s 313ms/step\n",
      "\n",
      " epoch: 23 - QWK_score: 0.754014 \n",
      "\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 127s 951ms/step - loss: 0.8985 - val_loss: 1.0512\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.03484\n",
      "24/24 [==============================] - 7s 308ms/step\n",
      "\n",
      " epoch: 24 - QWK_score: 0.785394 \n",
      "\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 131s 982ms/step - loss: 0.8783 - val_loss: 1.0438\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.03484\n",
      "24/24 [==============================] - 7s 304ms/step\n",
      "\n",
      " epoch: 25 - QWK_score: 0.785812 \n",
      "\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 127s 958ms/step - loss: 0.8896 - val_loss: 1.1629\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.03484\n",
      "24/24 [==============================] - 7s 306ms/step\n",
      "\n",
      " epoch: 26 - QWK_score: 0.779046 \n",
      "\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 125s 943ms/step - loss: 0.8739 - val_loss: 1.2238\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.03484\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "24/24 [==============================] - 7s 289ms/step\n",
      "\n",
      " epoch: 27 - QWK_score: 0.765034 \n",
      "\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 129s 969ms/step - loss: 0.8185 - val_loss: 1.0674\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.03484\n",
      "24/24 [==============================] - 8s 317ms/step\n",
      "\n",
      " epoch: 28 - QWK_score: 0.779770 \n",
      "\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 125s 939ms/step - loss: 0.8073 - val_loss: 1.1045\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.03484\n",
      "24/24 [==============================] - 7s 302ms/step\n",
      "\n",
      " epoch: 29 - QWK_score: 0.787960 \n",
      "\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 127s 956ms/step - loss: 0.8106 - val_loss: 1.0832\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.03484\n",
      "24/24 [==============================] - 7s 310ms/step\n",
      "\n",
      " epoch: 30 - QWK_score: 0.777473 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f78d3934400>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early, qwk]\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            # loss=kappa_loss,\n",
    "            optimizer=Adam(lr=1e-4))\n",
    "model.fit_generator(\n",
    "    train_mixup,\n",
    "    steps_per_epoch=np.ceil(float(len(train_x)) / float(batch_size)),\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_x)) / float(batch_size)),\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    workers=1, use_multiprocessing=False,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qv3D5CauvR5"
   },
   "outputs": [],
   "source": [
    "def predict(submit):\n",
    "    predicted = []\n",
    "    for i, path in tqdm(enumerate(submit)):\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.resize(image, (SIZE, SIZE))\n",
    "        X = np.array((image[np.newaxis])/255)\n",
    "        score_predict=((model.predict(X).ravel()*model.predict(X[:, ::-1, :, :]).ravel()*model.predict(X[:, ::-1, ::-1, :]).ravel()*model.predict(X[:, :, ::-1, :]).ravel())**0.25).tolist()\n",
    "        label_predict = np.argmax(score_predict)\n",
    "        predicted.append((label_predict))\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rVKuCaK_ZV9p",
    "outputId": "d839abd9-6fcb-4c89-9aa3-3fc604085122"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [01:02,  6.18it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "id": "04oSTcbYZ20l",
    "outputId": "6d0c016e-a23c-4c55-9e5b-9ff4064c6544"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c73d59eb95d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1 Score: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m   1058\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                          str(average_options))\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and multiclass targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F1 Score: \", f1_score(y_true, predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "CKYWcOltaKrG",
    "outputId": "ddbbc550-24d8-4a2f-f931-002b36233e92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmxuS1qKaNkE"
   },
   "outputs": [],
   "source": [
    "y_true = dataset[dataset['path'].isin(valid_x)]['level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQvSEmBnamzC"
   },
   "outputs": [],
   "source": [
    "y_true = get_level(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "colab_type": "code",
    "id": "n4eDL0yabXMH",
    "outputId": "cc1b61d0-28f8-4212-db12-d4907a59a25c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jidUNDqcbhi2"
   },
   "outputs": [],
   "source": [
    "model.save(\"dense_net_80kappa_wednesday.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsXbmQ-OcJRo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Blindness Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
